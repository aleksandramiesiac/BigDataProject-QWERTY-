{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+--------------------+------+------------+----------+--------------------+-----------+-----------+---------+-----+----------+----------+----+---------+\n",
      "|    Airline|Arrival_hour|           Arrive_to|Change|Country_from|Country_to|         Depart_from|Depart_hour|Flight_date|Flight_id|Price|Scrap_date|Scrap_time|Days|ThereBack|\n",
      "+-----------+------------+--------------------+------+------------+----------+--------------------+-----------+-----------+---------+-----+----------+----------+----+---------+\n",
      "|   Wizz Air|       04:10|         Bourgas BOJ|     1|     Austria|  Bulgaria|London LTNLondon ...|      22:40|   14/06/19|       35|70.15|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       07:15|London LTNLondon ...|     1|     Austria|  Bulgaria|         Bourgas BOJ|      05:25|   21/06/19|       35|20.45|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       16:10|          Vienna VIE|     1|     Austria|  Bulgaria|London LTNLondon ...|      12:45|   21/06/19|       35| 35.5|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       12:10|Berlin SXFBerlin ...|     1|     Austria|  Bulgaria|        Salzburg SZG|      10:50|   21/09/19|       35|11.81|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       18:55|           Varna VAR|     1|     Austria|  Bulgaria|Berlin SXFBerlin ...|      15:25|   21/09/19|       35|44.99|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       15:30|Berlin SXFBerlin ...|     1|     Austria|  Bulgaria|           Varna VAR|      14:00|   27/09/19|       35|31.54|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       19:50|        Salzburg SZG|     1|     Austria|  Bulgaria|Berlin SXFBerlin ...|      18:25|   27/09/19|       35|55.58|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       12:40|London LTNLondon ...|     1|     Austria|  Bulgaria|          Vienna VIE|      11:15|   16/06/19|       35|52.71|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       04:10|         Bourgas BOJ|     1|     Austria|  Bulgaria|London LTNLondon ...|      22:40|   16/06/19|       35|43.26|2019-05-07|     05:00|null|    There|\n",
      "|    Ryanair|       18:00|   Krakow KRK FR3715|     1|     Austria|  Bulgaria|         Bourgas BOJ|      17:05|   23/06/19|       35|33.08|2019-05-07|     05:00|null|    There|\n",
      "|Laudamotion|       23:40|          Vienna VIE|     1|     Austria|  Bulgaria|          Krakow KRK|      22:40|   23/06/19|       35|15.17|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       18:10|London LTNLondon ...|     1|     Austria|  Bulgaria|          Vienna VIE|      16:50|   21/06/19|       35|19.89|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       04:10|         Bourgas BOJ|     1|     Austria|  Bulgaria|London LTNLondon ...|      22:40|   21/06/19|       35| 49.1|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       07:15|London LTNLondon ...|     1|     Austria|  Bulgaria|         Bourgas BOJ|      05:25|   28/06/19|       35|20.45|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       16:10|          Vienna VIE|     1|     Austria|  Bulgaria|London LTNLondon ...|      12:45|   28/06/19|       35|55.58|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       12:25|London LTNLondon ...|     1|     Austria|  Bulgaria|          Vienna VIE|      11:10|   06/06/19|       35|24.88|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       04:10|         Bourgas BOJ|     1|     Austria|  Bulgaria|London LTNLondon ...|      22:40|   06/06/19|       35|29.22|2019-05-07|     05:00|null|    There|\n",
      "|   Wizz Air|       07:15|London LTNLondon ...|     1|     Austria|  Bulgaria|         Bourgas BOJ|      05:25|   14/06/19|       35|20.45|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       16:10|          Vienna VIE|     1|     Austria|  Bulgaria|London LTNLondon ...|      12:45|   14/06/19|       35|70.88|2019-05-07|     05:00|null|    There|\n",
      "|    easyJet|       12:25|London LTNLondon ...|     1|     Austria|  Bulgaria|          Vienna VIE|      11:10|   13/06/19|       35|20.33|2019-05-07|     05:00|null|    There|\n",
      "+-----------+------------+--------------------+------+------------+----------+--------------------+-----------+-----------+---------+-----+----------+----------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "import json\n",
    "\n",
    "conf = SparkConf().setAppName('MyFirstStandaloneApp')\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "filepath = \"./flights_reduces.text \"\n",
    "\n",
    "flightsRDD = sc.textFile(filepath)\n",
    "header = flightsRDD.first()\n",
    "filtered = flightsRDD.filter(lambda line: line != header)\n",
    "parts = filtered.map(lambda line: line.split(';'))\n",
    "# Robilem to na roboczym pliku, trzeba sprawdzic czy finalnie pokrywa sie ta kolejnosc kolumn\n",
    "flights = parts.map(lambda p:\n",
    "                   Row(Scrap_date = p[0],\n",
    "                       Scrap_time = p[1],\n",
    "                       Country_from = p[2],\n",
    "                       Country_to = p[3],\n",
    "                       Flight_id = int(p[4]),\n",
    "                       Flight_date = p[5],\n",
    "                       Airline = p[6],\n",
    "                       Change = int(p[7]),\n",
    "                       Price = float(p[8]),\n",
    "                       Depart_hour = p[9],\n",
    "                       Depart_from = p[10],\n",
    "                       Arrival_hour = p[11],\n",
    "                       Arrive_to = p[12]\n",
    "                      ))\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "dt = sqlContext.createDataFrame(flights)\n",
    "# To days cos nie dziala, tu musze poprawic, wczesniej dzialo, ale nie na wersji 1.6 i wrzucilem jakis kod ze stacka,\n",
    "# ale wyrzuca null\n",
    "dt = dt.withColumn(\"Days\", F.datediff(F.to_date(F.unix_timestamp( dt.Flight_date, \"dd/MM/yy\").cast(\"timestamp\")), \n",
    "                                    F.to_date(F.unix_timestamp( dt.Scrap_date, \"'yyyy-MM-dd\").cast(\"timestamp\"))))\n",
    "# Tutaj sobie dodaje kolumne roboczo ThereBack, w naszym pliku to bedzie, wiec mozna usunac\n",
    "dt = dt.withColumn(\"ThereBack\", F.lit('There'))\n",
    "dt.registerTempTable(\"flights\")\n",
    "dt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_sum.write.format('com.databricks.spark.csv').save('Price_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutaj poniżej jest taki przykładowy kod, jak wykonac filtrowanie np. zsumowac wszystkie ceny biletow w pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To mozna w jakims jsonie umiescic jako plik konfiguracyjny, ktory tam sie zmienia\n",
    "direction = 'There'\n",
    "country_from = 'Austria'\n",
    "country_to = 'Bulgaria'\n",
    "scrap_time = '05:00'\n",
    "\n",
    "query = \"SELECT * FROM flights WHERE Country_from = '{0}' AND Country_to = '{1}' \\\n",
    "AND Scrap_time = '{2}' AND ThereBack = '{3}'\".format(country_from, country_to, scrap_time, direction)\n",
    "\n",
    "test = sqlContext.sql(query)\n",
    "price_sum = test.agg(F.sum(dt.Price).alias('Price_sum'))\n",
    "#price_sum.rdd.map(lambda x: x).saveAsTextFile('Price_sum.csv')\n",
    "# Uwaga, tutaj jest problem, bo dziala mi to na lapku, ale nie dziala na tej maszynie wirtualnej... to zapisywanie do csv\n",
    "# No i oddziela przecinkami, a nie srednikami, tego trzeba poszukac\n",
    "# Jak raz wywolacie zapisywanie do jakiegos pliku to potem jak chcecie to odpalic jeszcze raz to pamietajcie, zeby\n",
    "# Usunac ten stary plik/folder co sie wygeneruje, bo wam wysypie bledy\n",
    "price_sum.write.format('com.databricks.spark.csv').save('Price_sum_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_proc = \"SELECT * FROM flights WHERE Country_from = '{0}' AND Country_to = '{1}'\".format(country_from, country_to)\n",
    "processed = sqlContext.sql(query_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrzę w ten sposób: chcę polecieć w podróż A-B, nieważne na jak długo, nie ważne kiedy jest lot, liczy się tylko cena przelotu z podziałem na czas kiedy taka występuje. Tutaj poniżej robię taki myk, że grupuję sobie po flight_id i patrzę jaka jest skumulowana cena każdej podróży. Później robię grupowanie po Scrap_date i Scrap_time, tak że dostaję tabelę z najniższą ceną podróży każdego dnia o porze skrapowania. Wydaje mi się, że jest to dobra tabela, żeby na jej podstawie zrobić jakąś regresję oraz wyplotować dane historyczne po dniach.\n",
    "W analogii do dplyr:\n",
    "groupBy to samowyjaśnialne, a agg to takie summarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+\n",
      "|Scrap_date|Scrap_time|            Price|\n",
      "+----------+----------+-----------------+\n",
      "|2019-05-07|     05:00|4367.999999999997|\n",
      "+----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = processed.groupBy([\"Flight_id\"]).agg(F.first(processed.Scrap_date).alias('Scrap_date'), \n",
    "                                            F.first(processed.Scrap_time).alias('Scrap_time'), \n",
    "                                             F.sum(processed.Price).alias(\"Price\"))\n",
    "df = df.groupBy([\"Scrap_date\", \"Scrap_time\"]).agg(F.min(df.Price).alias('Price'))\n",
    "df.show()\n",
    "df.write.format('com.databricks.spark.csv').save('Regression2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej robię taką ogólną tabelę, która jest odtworzeniem tej generalnej tabeli ze strony azair.eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = processed.groupBy([\"Flight_id\", \"Direction\"]).agg(\n",
    "    F.sum(processed.Price).alias(\"Price\"),\n",
    "    F.first(processed.Scrap_date).alias(\"Scrap_date\"),\n",
    "    F.first(processed.Flight_date).alias(\"Flight_date\"),\n",
    "    F.first(processed.Country_from).alias(\"Country_from\"),\n",
    "    F.first(processed.Country_to).alias(\"Country_to\"),\n",
    "    F.first(processed.Depart_hour).alias(\"Depart_hour\"),\n",
    "    F.first(processed.Depart_from).alias(\"Depart_from\"),\n",
    "    F.last(processed.Arrival_hour).alias(\"Arrival_hour\"),\n",
    "    F.last(processed.Arrive_to).alias(\"Arrive_to\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------+----------+-----------+------------+----------+-----------+--------------------+------------+--------------+\n",
      "|Flight_id|Direction|            Price|Scrap_date|Flight_date|Country_from|Country_to|Depart_hour|         Depart_from|Arrival_hour|     Arrive_to|\n",
      "+---------+---------+-----------------+----------+-----------+------------+----------+-----------+--------------------+------------+--------------+\n",
      "|       35|    There|4367.999999999997|2019-05-07|   14/06/19|     Austria|  Bulgaria|      22:40|London LTNLondon ...|       17:25|Klagenfurt KLU|\n",
      "+---------+---------+-----------------+----------+-----------+------------+----------+-----------+--------------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnie jak przy df1, ale grupuję sobie po Destination jeszcze, tak że mi sie rozbija na loty \"There\" i \"Back\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+-----+\n",
      "|Scrap_date|Scrap_time|Direction|Price|\n",
      "+----------+----------+---------+-----+\n",
      "|2019-05-07|     05:00|    There|11.81|\n",
      "+----------+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = processed.groupBy(\"Scrap_date\", \"Scrap_time\", \"Direction\").agg(\n",
    "    F.min(processed.Price).alias(\"Price\"),\n",
    ")\n",
    "df3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
