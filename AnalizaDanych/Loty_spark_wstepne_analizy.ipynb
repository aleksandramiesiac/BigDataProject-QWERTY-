{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names = []\n",
    "with open('columns.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        names.append(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scrap_date',\n",
       " 'Scrap_time',\n",
       " 'Country_from',\n",
       " 'Country_to',\n",
       " 'Flight_id',\n",
       " 'Flight_date',\n",
       " 'Airline',\n",
       " 'Change',\n",
       " 'Price',\n",
       " 'There_back',\n",
       " 'Depart_hour',\n",
       " 'Journey_from',\n",
       " 'Depart_from',\n",
       " 'Arrival_hour',\n",
       " 'Journey_to',\n",
       " 'Arrive_to']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dat = pd.DataFrame(columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scrap_date</th>\n",
       "      <th>Scrap_time</th>\n",
       "      <th>Country_from</th>\n",
       "      <th>Country_to</th>\n",
       "      <th>Flight_id</th>\n",
       "      <th>Flight_date</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Change</th>\n",
       "      <th>Price</th>\n",
       "      <th>There_back</th>\n",
       "      <th>Depart_hour</th>\n",
       "      <th>Journey_from</th>\n",
       "      <th>Depart_from</th>\n",
       "      <th>Arrival_hour</th>\n",
       "      <th>Journey_to</th>\n",
       "      <th>Arrive_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Scrap_date, Scrap_time, Country_from, Country_to, Flight_id, Flight_date, Airline, Change, Price, There_back, Depart_hour, Journey_from, Depart_from, Arrival_hour, Journey_to, Arrive_to]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dowolny filtr na podstawie pliku json. Tutaj trzeba dodać możliwość typu porównania dla wartości ilościowych, typu \"bigger\", \"equal\", \"less\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import json\n",
    "\n",
    "filepath = ''\n",
    "\n",
    "def custom_filter_generator(conf_path):\n",
    "    with open(conf_path) as json_file:  \n",
    "        configuration = json.load(json_file)\n",
    "    config = list(configuration.values())\n",
    "    indices = [i for i in range(len(config)) if config[i] != 'None']\n",
    "    return lambda x :  sum([x.split(';')[i] == config[i] for i in indices]) \n",
    "        \n",
    "    \n",
    "conf = SparkConf().setAppName(\"flights\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "flightsRDD = sc.textFile(filepath)\n",
    "header = flightsRDD.first()\n",
    "flightsRDD = flightsRDD.filter(lambda line: line != header)\n",
    "filer_rule = custom_filter_generator('conf.txt')\n",
    "routeRDD = flightsRDD.filter(filter_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyszukiwanie najtańszych połączeń dla zadanego filtra. Znajduje połączenie o najniższej cenie dla podanych parametrów filtrowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = peopleRDD.flatMap(lambda line: float(line.split(';')[8]))\n",
    "cheapest = prices.reduce(lambda x, y: min(x,y))\n",
    "cheapest_route = fligthsRDD.filter(lambda line : float(line.split(';')[8]) == cheapest)\n",
    "cheapest_route.saveAsTextFile('\\out\\filtered.text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W jakie dni i w jakich porach są najtańsze bilety dla danego połączenia (kraj - kraj). Analogicznie można robić z departure_from oraz departure_to. To samo przetwarzanie można zastosować przy sprawdzaniu jak zmieniały się ceny przewoźnika na danej linii. Tutaj zczytujemy tylko najniższą cenę podróży ( w obie strony), nie patrzymy jak daleko jest lot od daty dzisiejszej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "conf = SparkConf().setAppName(\"flights\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "country_from = 'France'\n",
    "country_to = 'Denmark'\n",
    "\n",
    "filepaths =  #lista list sciezek do plikow / nazw w kolejnosci : pon_0, pon_1, pon_2, pon_3, wt_0, wt_1, itd.\n",
    "mean_prices = []\n",
    "for filepath in filepaths:\n",
    "    flightsRDD = sc.textFile(filepath)\n",
    "    header = flightsRDD.first()\n",
    "    filtered = flightsRDD.filter(lambda line: line != header)\n",
    "    filtered = filtered.filter(lambda line: line.split(';')[2] == country_from and line.split(';')[3] == country_to)\n",
    "    pairRDD = filtered.map(lambda line: (float(line.split(';')[4]), float(line.split(';')[8])))\n",
    "    groupedByJourneyID = pairRDD.groupByKey()\n",
    "    pricesByJourney = groupedByJourneyID.reduceByKey(lambda x,y : x + y)\n",
    "    mean_prices.append(pricesByJourney.mapValues(lambda price: price).reduce(lambda x,y : mean(x,y)))\n",
    "\n",
    "# Tutaj jest przetwarzanie dla jednego tygodnia, oczywiscie zrobi sie dla kazdego, natomiast to zalezy jak te pliki beda\n",
    "# wygladaly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można analizować ceny biletów np. na danej linii, albo nawet na wszystkich liniach, ale moim zdaniem jak robimy analizę to jednak jesteśmy zazwyczaj zainteresowani jakimiś konkretnymi połączeniami. Jako klienci linii lotniczych, nie interesuje nas trend kiedy ceny w ogólności są najtańsze, ale kiedy są najtańsze na danej linii. Albo szukamy okazji i kupujemy jak coś się pojawi ad hoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liczy srednia cene podrozy (w dwie strony) pomiedzy dwoma krajami dla zadanego okresu wyprzedzenia kupna (okreslonego,\n",
    "# jako liczba dni pomiedzy sprawdzeniem ceny, a data odlotu). Niezaleznie od dnia i pory kupna biletu.\n",
    "\n",
    "from statistics import mean\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "conf = SparkConf().setAppName(\"flights\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "country_from = 'France'\n",
    "country_to = 'Denmark'\n",
    "time_from_check_to_flight = 8\n",
    "\n",
    "def daytime_filter_generator(days):\n",
    "    def daytime_filter(line: str):\n",
    "        time_from_check_to_flight = days\n",
    "        line = line.split(';')\n",
    "        scrap_day = datetime.datetime.strptime(line[0], '%Y-%m-%d')\n",
    "        flight_day = datetime.datetime.strptime(line[5], '%d/%m/%y')\n",
    "        return abs(flight_day - scrap_day) == datetime.timedelta(time_from_check_to_flight) and line[9] == \"There\"\n",
    "    return daytime_filter\n",
    "\n",
    "filepaths =  #lista list sciezek do plikow / nazw w kolejnosci : pon_0, pon_1, pon_2, pon_3, wt_0, wt_1, itd.\n",
    "p = 0\n",
    "n = 0\n",
    "for filepath in filepaths:\n",
    "    flightsRDD = sc.textFile(filepath)\n",
    "    header = flightsRDD.first()\n",
    "    flightsRDD = flightsRDD.filter(lambda line: line != header)\n",
    "    filtered = flightsRDD.filter(lambda line: line.split(';')[2] == country_from and line.split(';')[3] == country_to)\n",
    "    pairRDD = filtered.map(lambda line: (float(line.split(';')[4]), float(line.split(';')[8])))\n",
    "    groupedByJourneyID = pairRDD.groupByKey()\n",
    "    pricesByJourney = groupedByJourneyID.reduceByKey(lambda x,y : x + y)\n",
    "    daytime_filter = daytime_filter_generator(time_from_check_to_flight)\n",
    "    day_filtered = flightsRDD.filter(daytime_filter).map(lambda line: line.split(';')[4]).collect()\n",
    "    day_filtered = list(unique(np.array(day_filtered)))\n",
    "    for id_j , price in pricesByJourney.collect():\n",
    "        if id_j in day_filtered:\n",
    "            p += price\n",
    "    n += len(day_filtered)\n",
    "print(\"Mean price for {}-{} journey with {} days booking before flight: {}\" \\\n",
    "      .format(country_from, country_to, time_from_check_to_flight, p / n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
